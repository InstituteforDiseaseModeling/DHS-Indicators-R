{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17fcf032-02ce-430a-8064-0783bce6ae23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Set analysis options as variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d55ad76b-0d71-4d6d-88d2-5824125e66c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%r\n",
    "version <- \"7\"\n",
    "dry_run <- FALSE\n",
    "result_dir <- \"/dbfs/tmp/result\"\n",
    "volume_root <- \"/Volumes/idm_dhs_recode_dev_01\"\n",
    "\n",
    "files <- list.files(result_dir, recursive = TRUE, full.names = TRUE)\n",
    "file.remove(files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05858c21-b533-4811-ac7a-1e52b5d08338",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Get metadata from filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ecfea74-f822-4958-9cdd-912fdcf49e4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%r\n",
    "get_file_type <- function(filename) {\n",
    "  # Extract just the base filename (strip path)\n",
    "  base <- basename(filename)\n",
    "  \n",
    "  # Try to match; regexec returns -1 if no match\n",
    "  m <- regexec(\"^[A-Z]{2}(IR|MR|PR|HR|KR|BR|CR)\", base, perl = TRUE)\n",
    "  parts <- regmatches(base, m)[[1]]\n",
    "\n",
    "  # If length < 2, no capture was found\n",
    "  if (length(parts) < 2) {\n",
    "    survey_code <- NA\n",
    "  } else {\n",
    "    survey_code <- parts[2]\n",
    "  }\n",
    "  survey_code\n",
    "}\n",
    "\n",
    "get_country_code <- function(filename) {\n",
    "  basename <- basename(filename)\n",
    "  country_code <- substr(basename, 1, 2)\n",
    "  return(country_code)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46eb569e-7413-4911-9a05-3d957cb31846",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check chapter folder, must implement run_indicators.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb589125-87f1-43b5-b676-8e607fdbce94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%r\n",
    "\n",
    "find_chapter_folders <- function() {\n",
    "  chapter_dirs <- list.dirs(here::here(), recursive = FALSE)\n",
    "  chapter_dirs <- chapter_dirs[grepl(\"^Chap\", basename(chapter_dirs))]\n",
    "  valid_chapters <- list()\n",
    "  for (dir in chapter_dirs) {\n",
    "    chapter_name <- basename(dir)\n",
    "    if (file.exists(file.path(dir, \"run_indicators.R\"))) {\n",
    "      valid_chapters[[chapter_name]] <- dir\n",
    "    }\n",
    "  }\n",
    "  return(valid_chapters)\n",
    "}\n",
    "\n",
    "check_input_files <- function(chapter_path) {\n",
    "  required_files <- list(IR = FALSE, MR = FALSE, PR = FALSE, HR = FALSE, KR = FALSE, BR = FALSE, CR = FALSE)\n",
    "  run_indicators_path <- file.path(chapter_path, \"run_indicators.R\")\n",
    "  if (file.exists(run_indicators_path)) {\n",
    "    content <- readLines(run_indicators_path)\n",
    "    required_files$IR <- any(grepl(\"--ir=|IR.*dta|IR.*DTA\", content))\n",
    "    required_files$MR <- any(grepl(\"--mr=|MR.*dta|MR.*DTA\", content))\n",
    "    required_files$PR <- any(grepl(\"--pr=|PR.*dta|PR.*DTA\", content))\n",
    "    required_files$HR <- any(grepl(\"--hr=|HR.*dta|HR.*DTA\", content))\n",
    "    required_files$KR <- any(grepl(\"--kr=|KR.*dta|KR.*DTA\", content))\n",
    "    required_files$BR <- any(grepl(\"--br=|BR.*dta|BR.*DTA\", content))\n",
    "    required_files$CR <- any(grepl(\"--cr=|CR.*dta|CR.*DTA\", content))\n",
    "  }\n",
    "  return(required_files)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "144bc1f3-20bd-4649-9baa-1cbbfad30434",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Process files for country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ba25ce6-a9d6-49ad-a25a-df066d89e93f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%r\n",
    "# Define process_country_chapter function\n",
    " process_country_chapter <- function(country_code, chapter_info, files_by_type, dry_run = TRUE) {\n",
    "  chapter_name <- chapter_info$name\n",
    "  chapter_path <- chapter_info$path\n",
    "  required_files <- chapter_info$required_files\n",
    "  message(sprintf(\"Processing %s for chapter %s\", country_code, chapter_name))\n",
    "  cmd_params <- c()\n",
    "  \n",
    "  tryCatch({\n",
    "    for (file_type in names(required_files)) {\n",
    "      # message(paste0(\"file type:\", file_type))\n",
    "      if (required_files[[file_type]]) {\n",
    "        matching_files <- files_by_type[[file_type]]  \n",
    "        message(paste0(\"matching total:\", length(matching_files)))      \n",
    "        if (!is.null(matching_files)) {\n",
    "          # Filter by country code\n",
    "          country_filtered <- matching_files[tolower(get_country_code(matching_files)) == tolower(country_code)]\n",
    "          \n",
    "          if (length(country_filtered) > 0) {\n",
    "            # Further filter by version in the filename\n",
    "            pattern <- paste0(\"(?i)\", tolower(country_code), \".*\", version)\n",
    "            version_filtered <- country_filtered[grepl(pattern, basename(country_filtered), perl = TRUE)]\n",
    "\n",
    "            if (length(version_filtered) > 0) {\n",
    "              for (local_path in version_filtered) {\n",
    "                tryCatch({\n",
    "                  message(sprintf(\"Processing local file: %s\", local_path))\n",
    "                  \n",
    "                  # Make path absolute if necessary\n",
    "                  if (!fs::is_absolute_path(local_path)) {\n",
    "                    local_path <- fs::path_abs(local_path)\n",
    "                  }                  \n",
    "                  # Add command-line parameter for the tool\n",
    "                  cmd_param <- sprintf(\"--%s=%s\", tolower(file_type), normalizePath(local_path))\n",
    "                  # message(sprintf(\"Adding command parameter: %s\", cmd_param))\n",
    "                  \n",
    "                  cmd_params <- c(cmd_params, cmd_param)\n",
    "                 \n",
    "                }, error = function(e) {\n",
    "                  message(sprintf(\"Failed to process file %s: %s\", local_path, e$message))\n",
    "                })\n",
    "              }              \n",
    "           \n",
    "          } else {\n",
    "            message(sprintf(\"No %s files found for country %s\", file_type, country_code))\n",
    "            return(FALSE)\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    if (length(cmd_params) == 0) {\n",
    "      message(sprintf(\"No data files found for country %s, skipping\", country_code))\n",
    "      return(FALSE)\n",
    "    }\n",
    "    script_path <- NULL\n",
    "    if (file.exists(file.path(chapter_path, \"run_indicators.R\"))) {\n",
    "      script_path <- file.path(chapter_path, \"run_indicators.R\")\n",
    "    }\n",
    "    if (!is.null(script_path)) {\n",
    "      for (cmd_param in cmd_params){\n",
    "         cmd <- paste(\"Rscript\", script_path, paste(cmd_param, sprintf(\"--output-dir=%s\", result_dir), collapse = \" \"))\n",
    "         if (!dry_run) {\n",
    "          message(sprintf(\"Executing: %s\", cmd))\n",
    "          system(cmd)\n",
    "          } else {\n",
    "            message(sprintf(\"Would execute: %s\", cmd))\n",
    "          }\n",
    "      }\n",
    "    } else {\n",
    "      message(sprintf(\"No run_indicators.R found for chapter %s\", chapter_name))\n",
    "    }\n",
    "  }\n",
    "  return (TRUE)\n",
    "  }, error = function(e) {\n",
    "    message(sprintf(\"Error processing %s for chapter %s: %s\", country_code, chapter_name, e$message))\n",
    "    return(FALSE)\n",
    "  })\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8258f991-c9ad-4ab3-9244-e52d65dbe48f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Run the DHS indicator process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50e567b4-fbde-4c9d-ba40-58fe0008bb5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%r\n",
    "required_packages <- c(\"AzureStor\", \"AzureAuth\", \"tidyverse\", \"parallel\", \"optparse\", \"here\", \"fs\")\n",
    "missing_packages <- required_packages[!sapply(required_packages, requireNamespace, quietly = TRUE)]\n",
    "if (length(missing_packages) > 0) {\n",
    "  stop(paste(\"Missing required packages:\", paste(missing_packages, collapse = \", \")))\n",
    "}\n",
    "message(\"Starting DHS data analysis...\")\n",
    "message(\"Current working directory: \", getwd())\n",
    "  suppressPackageStartupMessages({\n",
    "    for (pkg in required_packages) {\n",
    "      library(pkg, character.only = TRUE)\n",
    "    }\n",
    "})\n",
    "\n",
    "# Piloting Countries\n",
    "countries <- read.csv(\"countries.csv\", stringsAsFactors = FALSE)\n",
    "\n",
    "# Find all chapter folders\n",
    "message(\"Finding chapter folders with run_indicators.R...\")\n",
    "chapter_folders <- find_chapter_folders()\n",
    "message(sprintf(\"Found %d valid chapter folders\", length(chapter_folders)))\n",
    "    \n",
    "# Create chapter info list with required files for each chapter\n",
    "chapter_info <- list()\n",
    "for (name in names(chapter_folders)) {\n",
    "  path <- chapter_folders[[name]]\n",
    "  required_files <- check_input_files(path)\n",
    "  if (!is.null(required_files)) {\n",
    "      message(sprintf(\"Chapter %s requires the following files:\", name))\n",
    "      for (file_type in names(required_files)) {\n",
    "          if (required_files[[file_type]]) {\n",
    "            message(sprintf(\"  %s: Required\", file_type))\n",
    "          }\n",
    "      }\n",
    "      chapter_info[[name]] <- list(\n",
    "        name = name,\n",
    "        path = path,\n",
    "        required_files = required_files\n",
    "      )\n",
    "  }\n",
    "}\n",
    "\n",
    "all_files <- c()\n",
    "files <- list.files(\n",
    "  path = volume_root,\n",
    "  pattern = \"\\\\.dta$\", # Match .dta files\n",
    "  recursive = TRUE, # Search subdirectories\n",
    "  full.names = TRUE,\n",
    "  ignore.case = TRUE \n",
    ")\n",
    "message(sprintf(\"Found %d total files\", length(files)))\n",
    "# Filter to only those in raw_dtas folders\n",
    "files <- files[grepl(\"raw_dtas/\", files)]\n",
    "all_files <- c(all_files, files)\n",
    "\n",
    "# for debugging\n",
    "df <- as.data.frame(t(unlist(all_files)))\n",
    "write.csv(df, \"all_files.csv\", row.names = FALSE)\n",
    "\n",
    "message(sprintf(\"Found %d files in DBFS volumes\", length(all_files)))\n",
    "\n",
    "files_by_type <- list()\n",
    "for (file_path in all_files) {\n",
    "  file_type <- get_file_type(file_path)\n",
    "  if (!is.na(file_type)) {\n",
    "    if (is.null(files_by_type[[file_type]])) {\n",
    "      files_by_type[[file_type]] <- character(0)\n",
    "    }\n",
    "    files_by_type[[file_type]] <- c(files_by_type[[file_type]], file_path)\n",
    "  }\n",
    "}\n",
    "country_codes <- unique(sapply(all_files, get_country_code))\n",
    "message(\"---------0000--------\")\n",
    "message(paste0(\" countries found:\", str(country_codes)))\n",
    "message(\"---------1111-------\")\n",
    "message(paste0(\" required :\", str(countries$file_prefix)))\n",
    "missing_prefixes <- setdiff(tolower(countries$file_prefix), tolower(country_codes))\n",
    "available_prefixes <- intersect(tolower(countries$file_prefix), tolower(country_codes))\n",
    "message(\"---------2222-------\")\n",
    "message(paste0(\" available for processing:\", str(available_prefixes)))\n",
    "if (length(missing_prefixes) > 0) {\n",
    "  message(\"The following file prefixes are in config but not found in Volume\")\n",
    "  print(countries[countries$file_prefix %in% missing_prefixes, c(\"file_prefix\", \"country_name\")])\n",
    "} else {\n",
    "  message(\"All configured file prefixes are present in Databricks Volume.\")\n",
    "}\n",
    "results <- list()\n",
    "for (ch_name in names(chapter_info)) {\n",
    "  ch_data <- chapter_info[[ch_name]]\n",
    "  message(sprintf(\"Processing chapter %s\", ch_name))\n",
    "  required_types <- names(ch_data$required_files)[unlist(ch_data$required_files)]\n",
    "  message(sprintf(\"Chapter %s requires file types: %s\", ch_name, paste(required_types, collapse = \", \")))\n",
    "  tasks <- list()\n",
    "  # loop over all countries found in volume\n",
    "  for (country in country_codes) {\n",
    "    task_id <- paste(country, ch_name, sep = \"_\")\n",
    "    tasks[[task_id]] <- list(country_code = country, chapter_info = ch_data)\n",
    "  }\n",
    "}\n",
    "# message(paste(tasks, collapse=\"\\n\"))\n",
    "\n",
    "# pre-allocate a vector to hold each task’s duration\n",
    "times <- numeric(length(tasks))\n",
    "\n",
    "# use lapply, loop over the indices so we can write into `times`\n",
    "ch_results <- lapply(seq_along(tasks), function(i) {\n",
    "  task  <- tasks[[i]]\n",
    "  start <- Sys.time()\n",
    "\n",
    "  ok <- tryCatch({\n",
    "    process_country_chapter(\n",
    "      task$country_code,\n",
    "      task$chapter_info,\n",
    "      files_by_type,\n",
    "      dry_run\n",
    "    )\n",
    "    TRUE\n",
    "  }, error = function(e) {\n",
    "    message(sprintf(\"Error processing country %s: %s\",\n",
    "                    task$country_code, e$message))\n",
    "    FALSE\n",
    "  })\n",
    "\n",
    "  # record how long this one took\n",
    "  times[i] <- as.numeric(Sys.time() - start, units = \"secs\")\n",
    "  ok\n",
    "})\n",
    "\n",
    "results       <- c(results, ch_results)\n",
    "success_count <- sum(unlist(results))\n",
    "message(sprintf(\"Completed processing. Success: %d/%d\", \n",
    "                success_count, length(results)))\n",
    "\n",
    "# see a quick run summary:\n",
    "data.frame(\n",
    "  country    = vapply(tasks, `[[`, \"\", \"country_code\"),\n",
    "  success    = unlist(ch_results),\n",
    "  time_secs  = times\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14fd3d2a-db27-4051-99d6-5f1264923efa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "source_dir = \"/dbfs/tmp/result/Chap07_FP\"\n",
    "# create report\n",
    "reports_dir = os.path.join(source_dir, \"reports\")\n",
    "index_file = os.path.join(source_dir, \"index.html\")\n",
    "\n",
    "# Collect HTML file paths\n",
    "html_files = [\n",
    "    f for f in os.listdir(reports_dir)\n",
    "    if f.endswith(\".html\") and os.path.isfile(os.path.join(reports_dir, f))\n",
    "]\n",
    "\n",
    "# Build HTML content\n",
    "html_lines = [\n",
    "    \"<!DOCTYPE html>\",\n",
    "    \"<html>\",\n",
    "    \"<head><meta charset='utf-8'><title>Family Planning Indicators Report</title></head>\",\n",
    "    \"<body>\",\n",
    "    \"<h1>Family Planning Indicators Report</h1>\",\n",
    "    \"<ul>\"\n",
    "]\n",
    "\n",
    "for file in sorted(html_files):\n",
    "    prefix = file.split(\"_\")[0]  # Get prefix before first underscore\n",
    "    href = os.path.join(\"reports\", file)\n",
    "    html_lines.append(f'  <li><a href=\"{href}\">{prefix}</a></li>')\n",
    "\n",
    "html_lines.extend([\n",
    "    \"</ul>\",\n",
    "    \"</body>\",\n",
    "    \"</html>\"\n",
    "])\n",
    "\n",
    "# Write index.html\n",
    "with open(index_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(html_lines))\n",
    "\n",
    "print(f\"index.html created at {index_file}\")\n",
    "\n",
    "# zip results\n",
    "\n",
    "output_zip = \"/tmp/data\"  \n",
    "shutil.make_archive(output_zip, 'zip', source_dir)\n",
    "\n",
    "shutil.move(\"/tmp/data.zip\", \"/dbfs/FileStore/data.zip\")\n",
    "\n",
    "print(f\"download link: https://adb-1652658079176617.17.azuredatabricks.net/files/data.zip\" )\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6094926025913023,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "run_dhs_analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
